{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "driver = webdriver.Chrome()\n",
    "url = \"https://akashadata.com/team/\"\n",
    "driver.get(url)\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "# next_page_button = driver.find_elements(By.XPATH,\"//a[@class='page-link' and text()='Next Page']\")\n",
    "\n",
    "# next_page_button[0].click()\n",
    "wait = WebDriverWait(driver, 20)\n",
    "element_present = EC.presence_of_element_located((By.CSS_SELECTOR, 'img.user-pic'))\n",
    "# wait.until(element_present)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "user_pics = driver.find_elements(By.CSS_SELECTOR, 'img.user-pic')\n",
    "\n",
    "img_urls = [img.get_attribute('src') for img in user_pics]\n",
    "names = [url.split('s/')[-1].split('.jpg')[0] for url in img_urls]\n",
    "\n",
    "name_sets = [names[i:i+8] for i in range(0, len(names), 8)]\n",
    "\n",
    "number_elements = driver.find_elements(By.CSS_SELECTOR, \".fs-7.text-muted.fw-bolder.pt-1.text-center\")\n",
    "\n",
    "# Extract the text from each element and save them in a list\n",
    "numbers = [int(element.text) for element in number_elements]\n",
    "\n",
    "current_df = pd.DataFrame({\n",
    "        'Name': name_sets,\n",
    "        'Number': numbers,\n",
    "        # 'URL': url\n",
    "        })\n",
    "current_df.to_csv(f'page_{1}.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"6cbc4b9fe01d981182820a0e0e468482\", element=\"547B04D01AA43FE8AC90AF0289F2834B_element_415\")>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_page_button = driver.find_elements(By.XPATH,\"//a[@class='page-link' and text()='Next Page']\")\n",
    "\n",
    "next_page_button[0].click()\n",
    "wait.until(element_present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_pics = driver.find_elements(By.CSS_SELECTOR, 'img.user-pic')\n",
    "\n",
    "img_urls = [img.get_attribute('src') for img in user_pics]\n",
    "names = [url.split('s/')[-1].split('.jpg')[0] for url in img_urls]\n",
    "\n",
    "name_sets = [names[i:i+8] for i in range(0, len(names), 8)]\n",
    "\n",
    "number_elements = driver.find_elements(By.CSS_SELECTOR, \".fs-7.text-muted.fw-bolder.pt-1.text-center\")\n",
    "\n",
    "# Extract the text from each element and save them in a list\n",
    "numbers = [int(element.text) for element in number_elements]\n",
    "\n",
    "current_df = pd.DataFrame({\n",
    "        'Name': name_sets,\n",
    "        'Number': numbers,\n",
    "        # 'URL': url\n",
    "        })\n",
    "current_df.to_csv(f'page_{5}.csv', index=False)\n",
    "next_page_button = driver.find_elements(By.XPATH,\"//a[@class='page-link' and text()='Next Page']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Next_Page(idx):\n",
    "    next_page_button = driver.find_elements(By.XPATH,\"//a[@class='page-link' and text()='Next Page']\")\n",
    "    for i in range(idx):\n",
    "        num = Number()\n",
    "        url,names = URL()\n",
    "        current_df = pd.DataFrame({\n",
    "        'Name': names,\n",
    "        # 'Number': num[i*8:(i+1)*8],\n",
    "        'URL': url\n",
    "         })\n",
    "        current_df.to_csv(f'page_{i}.csv', index=False)\n",
    "        \n",
    "        next_page_button[0].click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Number():\n",
    "\n",
    "\n",
    "    number_elements = driver.find_elements(By.CSS_SELECTOR, \".fs-7.text-muted.fw-bolder.pt-1.text-center\")\n",
    "\n",
    "# Extract the text from each element and save them in a list\n",
    "    numbers = [int(element.text) for element in number_elements]\n",
    "    return(numbers)\n",
    "    # print(numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def URL():\n",
    "    \n",
    "    user_pics = driver.find_elements(By.CSS_SELECTOR, 'img.user-pic')\n",
    "\n",
    "    # 获取所有图片的网址\n",
    "    img_urls = [img.get_attribute('src') for img in user_pics]\n",
    "    names = [url.split('s/')[-1].split('.jpg')[0] for url in img_urls]\n",
    "    return img_urls,names\n",
    "\n",
    "# 打印所有图片的网址\n",
    "# for url in img_urls:\n",
    "#     print(url)\n",
    "\n",
    "\n",
    "# 关闭浏览器\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 URLs      Names\n",
      "0   https://t.akashadata.com/xstatic/img/c/s/kokom...     kokomi\n",
      "1   https://t.akashadata.com/xstatic/img/c/s/yelan...      yelan\n",
      "2   https://t.akashadata.com/xstatic/img/c/s/shino...    shinobu\n",
      "3   https://t.akashadata.com/xstatic/img/c/s/nahid...     nahida\n",
      "4   https://t.akashadata.com/xstatic/img/c/s/xiang...  xiangling\n",
      "..                                                ...        ...\n",
      "75  https://t.akashadata.com/xstatic/img/c/s/nahid...     nahida\n",
      "76  https://t.akashadata.com/xstatic/img/c/s/xingq...    xingqiu\n",
      "77  https://t.akashadata.com/xstatic/img/c/s/zhong...    zhongli\n",
      "78  https://t.akashadata.com/xstatic/img/c/s/hutao...      hutao\n",
      "79  https://t.akashadata.com/xstatic/img/c/s/yelan...      yelan\n",
      "\n",
      "[80 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract names from URLs\n",
    "names = [url.split('s/')[-1].split('.jpg')[0] for url in img_urls]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'URLs': img_urls,\n",
    "    'Names': names\n",
    "})\n",
    "\n",
    "print(df)\n",
    "df.to_csv('Second page.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tableau",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
